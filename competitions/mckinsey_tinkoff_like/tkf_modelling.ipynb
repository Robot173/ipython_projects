{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Построение модели и предсказаний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_bRoccB2dRh6"
   },
   "outputs": [],
   "source": [
    "#!pip install imblearn\n",
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5qLf_j4yYZQe",
    "outputId": "180bf42f-91f7-4d24-e6b4-c3a0451bf0f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%pylab inline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, make_scorer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "z1zPk7PZXxQI",
    "outputId": "013b196d-7aa1-4e25-d036-065a551c52aa",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3rXBy3GNqD7y"
   },
   "source": [
    "## Дообработка обучающей выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XGNaWKRKXIrc"
   },
   "outputs": [],
   "source": [
    "reaction_df = pd.read_csv('/content/drive/My Drive/tinkoff_data/refined_data/final_train.csv')\n",
    "reaction_test = pd.read_csv('/content/drive/My Drive/tinkoff_data/refined_data/final_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "oSSfhunAsVKL",
    "outputId": "81091cea-155b-4f0e-ecd9-775664640a15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                0\n",
       "children_cnt       0\n",
       "children_cnt_na    0\n",
       "g_F                0\n",
       "g_M                0\n",
       "                  ..\n",
       "wednesday          0\n",
       "thursday           0\n",
       "friday             0\n",
       "saturday           0\n",
       "sunday             0\n",
       "Length: 93, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reaction_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xdcn-FBwsYaS"
   },
   "outputs": [],
   "source": [
    "X, y = reaction_df.drop(columns=['event']), reaction_df['event']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F_XfbaRsscXY"
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=.2)\n",
    "\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_sample(X_train, y_train)\n",
    "\n",
    "X_resampled = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "y_resampled = pd.DataFrame(y_resampled, columns=['target'])['target']\n",
    "X_train, y_train = X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ugWAHX_Msgdx"
   },
   "source": [
    "## Функции для моделирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4qwQDjIusf1v"
   },
   "outputs": [],
   "source": [
    "#Простая кросс-валидация\n",
    "def test_modelling(Model):\n",
    "    scores = cross_val_score(Model, X, y, cv=3)\n",
    "    print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MuVOqgBTsnCX"
   },
   "outputs": [],
   "source": [
    "#Переход от классификации реакции к оценке\n",
    "def transform_results(predictions, alpha, is_rough=False): \n",
    "    is_good = predictions[:,1] + predictions[:,3] #Вероятность, что лайк + вероятность, что посмотрят\n",
    "    is_bad = predictions[:,0] + predictions[:,2] #Вероятность, что дизлайк + вероятность, что пропустят\n",
    "    result = is_good - is_bad \n",
    "    if is_rough:\n",
    "        result[result == 0] = -1\n",
    "    result[result > alpha] = 1\n",
    "    result[result < -alpha] = -1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A65biNtCsnFk"
   },
   "outputs": [],
   "source": [
    "#Проверка с помощью оверсэмплинга на основе матрицы значений\n",
    "def over_sampling_check(model, X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)\n",
    "    ros = RandomOverSampler(random_state=0)\n",
    "    X_resampled, y_resampled = ros.fit_sample(X_train, y_train)\n",
    "\n",
    "    X_resampled = pd.DataFrame(X_resampled, columns=X_train.columns)\n",
    "    y_resampled = pd.DataFrame(y_resampled, columns=['target'])['target']\n",
    "    X_train, y_train = X_resampled, y_resampled\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    m = np.array(confusion_matrix(y_test, predictions, labels=['like', 'view', 'skip', 'dislike']))\n",
    "    print(m)\n",
    "    return (m[0:2, 0:2].sum() + m[2:4, 2:4].sum())/m.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8qxdjzc9sp2J"
   },
   "outputs": [],
   "source": [
    "#Словарь значений, которые использовали организаторы при оценке\n",
    "label_to_vc_value = {'dislike':-10, 'like':0.5, 'skip':-0.1, 'view':0.1}\n",
    "\n",
    "#Проверка работы алгоритма при разных способах перехода от классификации реакции к бинарной классификации\n",
    "def testing_model_by_vc_grader(model, X_train, y_train, X_valid, y_valid,\n",
    "                               alpha=0.2, beta=1, transforming='classic'):\n",
    "    y_true = np.array([label_to_vc_value[val] for val in y_valid])\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict_proba(X_valid)\n",
    "    result = (predictions[:,1]*beta + predictions[:,3]) - (predictions[:,0]*beta + predictions[:,2])\n",
    "    if transforming == 'classic':\n",
    "        result[result >= 0] = 1\n",
    "        result[result <= 0] = -1\n",
    "    elif transforming == 'thresh':\n",
    "        result[result >= alpha] = 1\n",
    "        result[result <= -alpha] = -1\n",
    "    elif transforming == 'multiple':\n",
    "        results = []\n",
    "        for value in alpha:\n",
    "            result = (predictions[:,1]*beta + predictions[:,3]) - (predictions[:,0]*beta + predictions[:,2])\n",
    "            result[result >= value] = 1\n",
    "            result[result <= -value] = -1\n",
    "            results.append([value, sum(y_true*result)/sum(abs(y_true))])\n",
    "        return results\n",
    "    elif transforming == 'multiple_thresh':\n",
    "        results = []\n",
    "        for value in alpha:\n",
    "            result = (predictions[:,1]*beta + predictions[:,3]) - (predictions[:,0]*beta + predictions[:,2])\n",
    "            result[result >= value] = 1\n",
    "            result[result <= value] = -1\n",
    "            results.append([value, sum(y_true*result)/sum(abs(y_true))])\n",
    "        return results\n",
    "    return sum(y_true*result)/sum(abs(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tk47SAtqsnI6"
   },
   "outputs": [],
   "source": [
    "label_to_value = {'dislike':-1, 'like':1, 'skip':-1, 'view':1}\n",
    "#Вспомогательная функция для создания пользовательского scorer'а\n",
    "\n",
    "def score_func_tovalue(y, y_pred, transforming='classic', alpha=0, beta=1):\n",
    "    y_true = np.array([label_to_value[val] for val in y])\n",
    "    result = (y_pred[:,1]*beta + y_pred[:,3]) - (y_pred[:,0]*beta + y_pred[:,2])\n",
    "    result[result >= alpha] = 1\n",
    "    result[result <= -alpha] = -1\n",
    "    return mean_squared_error(y_true, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Zgplac3sr3y"
   },
   "outputs": [],
   "source": [
    "#Пользовательские scorer'ы\n",
    "\n",
    "new_scorer = make_scorer(score_func_tovalue, needs_proba=True)\n",
    "new_scorer2 = make_scorer(score_func_tovalue, needs_proba=True, greater_is_better=False, transforming='thresh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Моделирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 799
    },
    "colab_type": "code",
    "id": "iUbcPE_wtA4K",
    "outputId": "07fc9bac-efb0-406d-cfdb-0d14208a0fe0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] subsample=0.85, reg_alpha=0.01, colsample_bytree=0.8 ............\n",
      "[CV]  subsample=0.85, reg_alpha=0.01, colsample_bytree=0.8, score=-1.114, total=34.9min\n",
      "[CV] subsample=0.85, reg_alpha=0.01, colsample_bytree=0.8 ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 34.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.85, reg_alpha=0.01, colsample_bytree=0.8, score=-1.092, total=35.2min\n",
      "[CV] subsample=0.85, reg_alpha=0.001, colsample_bytree=0.8 ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 70.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.85, reg_alpha=0.001, colsample_bytree=0.8, score=-1.114, total=35.5min\n",
      "[CV] subsample=0.85, reg_alpha=0.001, colsample_bytree=0.8 ...........\n",
      "[CV]  subsample=0.85, reg_alpha=0.001, colsample_bytree=0.8, score=-1.085, total=36.3min\n",
      "[CV] subsample=0.85, reg_alpha=0.001, colsample_bytree=0.85 ..........\n",
      "[CV]  subsample=0.85, reg_alpha=0.001, colsample_bytree=0.85, score=-1.112, total=37.6min\n",
      "[CV] subsample=0.85, reg_alpha=0.001, colsample_bytree=0.85 ..........\n",
      "[CV]  subsample=0.85, reg_alpha=0.001, colsample_bytree=0.85, score=-1.085, total=36.8min\n",
      "[CV] subsample=0.8, reg_alpha=0.005, colsample_bytree=0.85 ...........\n",
      "[CV]  subsample=0.8, reg_alpha=0.005, colsample_bytree=0.85, score=-1.102, total=37.7min\n",
      "[CV] subsample=0.8, reg_alpha=0.005, colsample_bytree=0.85 ...........\n",
      "[CV]  subsample=0.8, reg_alpha=0.005, colsample_bytree=0.85, score=-1.085, total=37.8min\n",
      "[CV] subsample=0.85, reg_alpha=0.05, colsample_bytree=0.8 ............\n",
      "[CV]  subsample=0.85, reg_alpha=0.05, colsample_bytree=0.8, score=-1.111, total=34.6min\n",
      "[CV] subsample=0.85, reg_alpha=0.05, colsample_bytree=0.8 ............\n",
      "[CV]  subsample=0.85, reg_alpha=0.05, colsample_bytree=0.8, score=-1.093, total=35.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed: 361.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=2, error_score='raise-deprecating',\n",
       "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                           colsample_bylevel=1,\n",
       "                                           colsample_bynode=1,\n",
       "                                           colsample_bytree=1, gamma=0.1,\n",
       "                                           kvargs={'tree_method': 'gpu_hist'},\n",
       "                                           learning_rate=0.1, max_delta_step=0,\n",
       "                                           max_depth=6, min_child_weight=4,\n",
       "                                           missing=None, n_estimators=400,\n",
       "                                           n_jobs=1, nthread=None,\n",
       "                                           objective='binary:...\n",
       "                                           verbosity=1),\n",
       "                   iid='warn', n_iter=5, n_jobs=None,\n",
       "                   param_distributions={'colsample_bytree': [0.75, 0.8, 0.85],\n",
       "                                        'reg_alpha': [0, 0.001, 0.005, 0.01,\n",
       "                                                      0.05],\n",
       "                                        'subsample': [0.75, 0.8, 0.85]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False,\n",
       "                   scoring=make_scorer(score_func_tovalue, greater_is_better=False, needs_proba=True, transforming=thresh),\n",
       "                   verbose=3)"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Подбор гиперпараметров на XGBoost\n",
    "\n",
    "params = {\n",
    " 'subsample':[i/100.0 for i in range(75,90,5)],\n",
    " 'colsample_bytree':[i/100.0 for i in range(75,90,5)],\n",
    " 'reg_alpha':[0, 0.001, 0.005, 0.01, 0.05],\n",
    "}\n",
    "model = XGBClassifier(learning_rate=0.1, max_depth=6, min_child_weight=4, gamma=0.1, n_estimators=400, kvargs={'tree_method':'gpu_hist'})\n",
    "clf = RandomizedSearchCV(model, params, n_iter=5, cv=2, scoring=new_scorer2, verbose=3)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "rpg9NAoBnpRR",
    "outputId": "f8c15864-cb9e-4991-fda2-edfd8c01124a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'colsample_bytree': 0.85, 'reg_alpha': 0.005, 'subsample': 0.8},\n",
       " -1.0932464045586627)"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(clf.best_params_, clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ooeXDbDvng5x"
   },
   "outputs": [],
   "source": [
    "n_estimators = [135, 140, 145, 150]\n",
    "max_depth = [36, 38, 40, 42]\n",
    "min_samples_split = [3, 5]\n",
    "min_samples_leaf = [2, 5]\n",
    "hyperF = dict(n_estimators = n_estimators, max_depth = max_depth,\n",
    "              min_samples_split = min_samples_split, \n",
    "             min_samples_leaf = min_samples_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "colab_type": "code",
    "id": "WfOfM12wnku4",
    "outputId": "21ac4ae3-5b37-42e0-e9f4-0b1c50b2ffaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] n_estimators=150, min_samples_split=3, min_samples_leaf=5, max_depth=36 \n",
      "[CV]  n_estimators=150, min_samples_split=3, min_samples_leaf=5, max_depth=36, score=-0.706, total= 8.2min\n",
      "[CV] n_estimators=150, min_samples_split=3, min_samples_leaf=5, max_depth=36 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  8.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=150, min_samples_split=3, min_samples_leaf=5, max_depth=36, score=-0.701, total= 8.1min\n",
      "[CV] n_estimators=150, min_samples_split=3, min_samples_leaf=5, max_depth=36 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 16.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=150, min_samples_split=3, min_samples_leaf=5, max_depth=36, score=-0.601, total= 7.5min\n",
      "[CV] n_estimators=140, min_samples_split=3, min_samples_leaf=2, max_depth=40 \n",
      "[CV]  n_estimators=140, min_samples_split=3, min_samples_leaf=2, max_depth=40, score=-0.605, total= 7.3min\n",
      "[CV] n_estimators=140, min_samples_split=3, min_samples_leaf=2, max_depth=40 \n",
      "[CV]  n_estimators=140, min_samples_split=3, min_samples_leaf=2, max_depth=40, score=-0.598, total= 7.1min\n",
      "[CV] n_estimators=140, min_samples_split=3, min_samples_leaf=2, max_depth=40 \n",
      "[CV]  n_estimators=140, min_samples_split=3, min_samples_leaf=2, max_depth=40, score=-0.427, total= 7.3min\n",
      "[CV] n_estimators=135, min_samples_split=3, min_samples_leaf=5, max_depth=42 \n",
      "[CV]  n_estimators=135, min_samples_split=3, min_samples_leaf=5, max_depth=42, score=-0.699, total= 6.6min\n",
      "[CV] n_estimators=135, min_samples_split=3, min_samples_leaf=5, max_depth=42 \n",
      "[CV]  n_estimators=135, min_samples_split=3, min_samples_leaf=5, max_depth=42, score=-0.694, total= 6.3min\n",
      "[CV] n_estimators=135, min_samples_split=3, min_samples_leaf=5, max_depth=42 \n",
      "[CV]  n_estimators=135, min_samples_split=3, min_samples_leaf=5, max_depth=42, score=-0.593, total= 6.2min\n",
      "[CV] n_estimators=150, min_samples_split=5, min_samples_leaf=2, max_depth=38 \n",
      "[CV]  n_estimators=150, min_samples_split=5, min_samples_leaf=2, max_depth=38, score=-0.609, total= 7.2min\n",
      "[CV] n_estimators=150, min_samples_split=5, min_samples_leaf=2, max_depth=38 \n",
      "[CV]  n_estimators=150, min_samples_split=5, min_samples_leaf=2, max_depth=38, score=-0.603, total= 7.3min\n",
      "[CV] n_estimators=150, min_samples_split=5, min_samples_leaf=2, max_depth=38 \n",
      "[CV]  n_estimators=150, min_samples_split=5, min_samples_leaf=2, max_depth=38, score=-0.436, total= 7.3min\n",
      "[CV] n_estimators=135, min_samples_split=5, min_samples_leaf=2, max_depth=40 \n",
      "[CV]  n_estimators=135, min_samples_split=5, min_samples_leaf=2, max_depth=40, score=-0.610, total= 6.5min\n",
      "[CV] n_estimators=135, min_samples_split=5, min_samples_leaf=2, max_depth=40 \n",
      "[CV]  n_estimators=135, min_samples_split=5, min_samples_leaf=2, max_depth=40, score=-0.602, total= 6.5min\n",
      "[CV] n_estimators=135, min_samples_split=5, min_samples_leaf=2, max_depth=40 \n",
      "[CV]  n_estimators=135, min_samples_split=5, min_samples_leaf=2, max_depth=40, score=-0.434, total= 6.7min\n",
      "[CV] n_estimators=140, min_samples_split=5, min_samples_leaf=5, max_depth=38 \n",
      "[CV]  n_estimators=140, min_samples_split=5, min_samples_leaf=5, max_depth=38, score=-0.703, total= 7.0min\n",
      "[CV] n_estimators=140, min_samples_split=5, min_samples_leaf=5, max_depth=38 \n",
      "[CV]  n_estimators=140, min_samples_split=5, min_samples_leaf=5, max_depth=38, score=-0.698, total= 6.8min\n",
      "[CV] n_estimators=140, min_samples_split=5, min_samples_leaf=5, max_depth=38 \n"
     ]
    }
   ],
   "source": [
    "#Подбор гиперпараметров на RandomForest\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "clf = RandomizedSearchCV(model, hyperF, cv=3, n_iter=10, scoring=new_scorer2, verbose=3)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "(clf.best_params_, clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EiTX_H_e-9aJ"
   },
   "source": [
    "Параметры BaggingClassifier были подобраны аналогично RandomForestClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KkHk6-NgoV7J"
   },
   "outputs": [],
   "source": [
    "#Объединение предыдущих трёх моделей в VotingClassifier\n",
    "\n",
    "model1 = BaggingClassifier(DecisionTreeClassifier(max_depth=40), n_estimators=120, max_samples=200000, max_features=0.6)\n",
    "model2 = XGBClassifier(learning_rate=0.005, gamma=0.1, n_estimators=400, max_depth=6, min_child_weight=4, subsample=0.8, colsample_bytree=0.85, kvargs={'tree_method':'gpu_hist'})\n",
    "model3 = RandomForestClassifier(n_estimators=150, min_samples_split=3, min_samples_leaf=2, max_depth=42)\n",
    "model4 = VotingClassifier(estimators=[('rf', model3), \n",
    "                                       ('gb', model2),\n",
    "                                     ('bc', model1)], voting='soft', weights=[1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "jIpUe22ftOuj",
    "outputId": "fc3c740c-5c74-4caa-a7e0-97294d59d1ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 55min 43s, sys: 5.27 s, total: 1h 55min 48s\n",
      "Wall time: 1h 55min 54s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.0, 0.2602035579532531],\n",
       " [0.1, 0.2625371986525398],\n",
       " [0.2, 0.24480689378734768],\n",
       " [0.30000000000000004, 0.22262944576608315],\n",
       " [0.4, 0.19419545881097047],\n",
       " [0.5, 0.17460195323910171],\n",
       " [0.6000000000000001, 0.1546384462358769],\n",
       " [0.7000000000000001, 0.14044802968341943],\n",
       " [0.8, 0.13361943033579157],\n",
       " [0.9, 0.130997637771487]]"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Проверка работы\n",
    "\n",
    "%%time\n",
    "testing_model_by_vc_grader(model4,\n",
    "                           X_train, y_train, X_valid, y_valid, \n",
    "                           alpha=np.arange(0,1,0.1), transforming='multiple')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0pAunt8EtgX7"
   },
   "source": [
    "## Сборка ответа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "colab_type": "code",
    "id": "aHR9GRzeuRmf",
    "outputId": "12df71ac-c3d5-4887-c757-c40c4f839988"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 1min 59s, sys: 10.1 s, total: 1h 2min 9s\n",
      "Wall time: 1h 2min 14s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('rf',\n",
       "                              RandomForestClassifier(bootstrap=True,\n",
       "                                                     class_weight=None,\n",
       "                                                     criterion='gini',\n",
       "                                                     max_depth=42,\n",
       "                                                     max_features='auto',\n",
       "                                                     max_leaf_nodes=None,\n",
       "                                                     min_impurity_decrease=0.0,\n",
       "                                                     min_impurity_split=None,\n",
       "                                                     min_samples_leaf=2,\n",
       "                                                     min_samples_split=3,\n",
       "                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                     n_estimators=150,\n",
       "                                                     n_jobs=None,\n",
       "                                                     oob_score=False,\n",
       "                                                     random_state=None,\n",
       "                                                     verbose=...\n",
       "                                                                                      min_samples_leaf=1,\n",
       "                                                                                      min_samples_split=2,\n",
       "                                                                                      min_weight_fraction_leaf=0.0,\n",
       "                                                                                      presort=False,\n",
       "                                                                                      random_state=None,\n",
       "                                                                                      splitter='best'),\n",
       "                                                bootstrap=True,\n",
       "                                                bootstrap_features=False,\n",
       "                                                max_features=0.6,\n",
       "                                                max_samples=200000,\n",
       "                                                n_estimators=120, n_jobs=None,\n",
       "                                                oob_score=False,\n",
       "                                                random_state=None, verbose=0,\n",
       "                                                warm_start=False))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='soft',\n",
       "                 weights=[1, 1, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model4.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "UamQWAI2uj6H",
    "outputId": "2eabe2ed-d2fe-4142-938c-094a70a7b406"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0036697 , 0.19037236, 0.24773926, 0.55821866],\n",
       "       [0.00905989, 0.18622493, 0.16862265, 0.63609252],\n",
       "       [0.0027843 , 0.15074268, 0.26865843, 0.57781458],\n",
       "       ...,\n",
       "       [0.00696839, 0.0332706 , 0.57441983, 0.38534118],\n",
       "       [0.00631807, 0.04526558, 0.53827998, 0.41013637],\n",
       "       [0.00670679, 0.08561341, 0.42737048, 0.48030933]])"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reaction_test = reaction_test.drop(columns=['answer_id'])\n",
    "predictions = model4.predict_proba(reaction_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9YfyxjiquvEf"
   },
   "outputs": [],
   "source": [
    "def transform_results(predictions): \n",
    "    is_good = predictions[:,1] + predictions[:,3]\n",
    "    is_bad = predictions[:,0] + predictions[:,2]\n",
    "    result = is_good - is_bad\n",
    "    result[result >= 0.2] = 1\n",
    "    result[result <= 0] = -1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "01nz2WrIuwWC",
    "outputId": "088a1c1a-fd8e-426e-875e-3b3cbbdee9de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  1.        ,  1.        , ..., -1.        ,\n",
       "       -1.        ,  0.13184547])"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = transform_results(predictions)\n",
    "transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "Yndu0WQXuyfE",
    "outputId": "b5474123-6b1e-4ff6-99f0-93149efda8c7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           score\n",
       "answer_id       \n",
       "0            1.0\n",
       "1            1.0\n",
       "2            1.0\n",
       "3            1.0\n",
       "4            1.0"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transformed = pd.DataFrame(transformed)\n",
    "df_transformed.columns=['score']\n",
    "df_transformed.index.name = 'answer_id'\n",
    "df_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TtoXEsEbuzp2"
   },
   "outputs": [],
   "source": [
    "df_transformed.to_csv(\"submission.csv\", sep=',', index=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "final_tkf.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
